{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classifier for personal attacks with the Wikipedia Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import urllib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# panda-fy the data\n",
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LogReg in SKLearn doesn't support continuous vars, so use a 'voting' methodology to determine classification\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279             Iraq is not good  ===  ===  USA is bad   \n",
       "2702703      ____ fuck off you little asshole. If you wan...\n",
       "4632658         i have a dick, its bigger than yours! hahaha\n",
       "6545332      == renault ==  you sad little bpy for drivin...\n",
       "6545351      == renault ==  you sad little bo for driving...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.query('attack')['comment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.953\n"
     ]
    }
   ],
   "source": [
    "# fit a Log Reg with character ngrams between 1 and 5 (takes a while)\n",
    "\n",
    "# note that the data already has train/test labels\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,5), analyzer='word', norm='l2')),\n",
    "    ('clf', LogisticRegression(C=1, penalty='l1')),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "auc = roc_auc_score(test_comments['attack'], clf.predict_proba(test_comments['comment'])[:, 1])\n",
    "print('Test ROC AUC: %.3f' %auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False], dtype=bool)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment with obfuscations\n",
    "clf.predict(['You are a f** cu*t!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKS ON OBFUSCATED CHARACTERS !!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['f*k you you lame', \n",
    "             'i hate you', \n",
    "             'Diane Abbott is a champion for rape victims',\n",
    "             \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/interim/aggregated.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean contents\n",
    "def remove_handles(text):\n",
    "    return re.sub('@[^\\s]+','',text)\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    return re.sub('#[^\\s]+',string=text,repl='')\n",
    "\n",
    "def remove_RT(text):\n",
    "    return re.sub('^RT ',string=text,repl='')\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub('http[^\\s]+',string=text,repl='')\n",
    "\n",
    "def process_text(text):\n",
    "    return (remove_url(remove_RT(remove_hashtags(remove_handles(text))))).strip()\n",
    "\n",
    "def process_text_ht(text):\n",
    "    return (remove_url(remove_RT(remove_handles(text)))).strip()\n",
    "\n",
    "df['Clean Contents'] = df['Contents'].map(process_text_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classify\n",
    "df['abusive'] = df['Clean Contents'].map(lambda x: clf.predict([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(df['abusive'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['abusive']]['Clean Contents'].head(20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
